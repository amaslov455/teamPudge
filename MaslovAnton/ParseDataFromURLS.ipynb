{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled5.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1mMh4I1Qn0MNrpVEvbe2F5xZosJOZdw8q","authorship_tag":"ABX9TyMUYLZPpNmmj/9X2BJbvvQ0"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KQMrvdqjqfmG","colab_type":"code","colab":{}},"source":["import requests\n","import time\n","import pandas as pd\n","import urllib3\n","from multiprocessing.dummy import Pool\n","from bs4 import BeautifulSoup as bs\n","from bs4 import Comment\n","from bs4 import Doctype"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hzmkCy5qvjv5","colab_type":"text"},"source":["Функция, которая подключается к сайту и забирает из его html весь текст без тегов, записывая текст из title в первую переменную, из description - во вторую, а оставшийся текст - в третью.\n","После возвращает все три переменнные <br>\n","Если же подключение к сайту не было успешным - возвращает none"]},{"cell_type":"code","metadata":{"id":"rStwtpQqql2L","colab_type":"code","colab":{}},"source":["def title_parser(url):\n","    try:\n","        request = session.get(url,headers = headers,verify=False, timeout=10)\n","        if request.status_code == 200:\n","            soup = bs(request.content, 'html.parser', from_encoding='utf-8-sig')\n","            [c.extract() for c in soup.find_all(string=lambda text: isinstance(text, Comment))]\n","            [item.extract() for item in soup if isinstance(item, Doctype)]\n","            [tag.decompose() for tag in soup(\"script\")]\n","            [tag.decompose() for tag in soup(\"style\")]\n","            \n","            title = soup.find('title').get_text()\n","            [tag.decompose() for tag in soup(\"title\")]\n","\n","            try:\n","                meta_tag = soup.find('meta', attrs={'name': 'description'})['content']\n","            except:\n","                meta_tag = ''\n","            content = '.'.join(soup.findAll(text=True))\n","            content = [value for value in content.split() if value != '' and value != '.']\n","            content = ' '.join(content)\n","            content = ' '.join(content.split(' .'))\n","            \n","            return title, meta_tag, content\n","        else:\n","            return 'none','none','none'\n","    except :\n","        print(\"Ошибка \" + url)\n","        return 'none','none','none'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"naAq-a3jyCMr","colab_type":"text"},"source":["Подключается датасет с url, категорией и подкатегорией сатой, поготовленный заранее <br>\n","Датасет делится на части по 1000 сайтов в каждой, после, используя мультитрединг, url каждой части прогоняются через вышеописанную функцию title_parser, возвращенные данные записываются в отдельные столбики и текущая часть датасета сохраняется"]},{"cell_type":"code","metadata":{"id":"N0PHvsRt5ouC","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","    headers = {\n","    'Accept' : '*/*',\n","    'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'\n","    }\n","\n","    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","    session = requests.Session()\n","\n","    df = pd.read_csv('/content/drive/My Drive/mailClassifier/mail_toparse_1_1.csv', encoding='utf-8-sig') \n","    df = df.drop('Unnamed: 0', 1)\n","\n","    dflen = len(df)\n","    for i in range(-(-dflen//1000)):\n","      if i>=0:\n","        start_time = time.time()\n","        print(i)\n","\n","        df1 = df[1000*i:1000*(i+1)]\n","        urls = df1['url'].to_list()\n","\n","        with Pool(20) as p:\n","            titles, desc, content = zip(*p.map(title_parser, urls))\n","\n","        df1['title'] = list(titles)\n","        df1['description'] = list(desc)\n","        df1['content'] = list(content)\n","        \n","        try:\n","          print('Start saving...')\n","          if i == 0:\n","              with open('/content/drive/My Drive/mailClassifier/mail_parsed_1_1.csv', 'w', encoding='utf-8-sig',newline='') as f:\n","                  df1.to_csv(f, header=True)\n","          else:\n","              with open('/content/drive/My Drive/mailClassifier/mail_parsed_1_1.csv', 'a', encoding='utf-8-sig',newline='') as f:\n","                  df1.to_csv(f, header=False)\n","        except:\n","          pass\n","\n","        print(f\"{(time.time() - start_time)} секунд\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9GcaRjWMqN_0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}